{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.3 Exercises - Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "From the datasets folder, load in the `dupedata.csv` file as a dataframe. Drop the duplicates from the dataframe, keeping the first value (save the resulting dataframe to a new variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries to use functions on dataframes\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the path to the file as a string\n",
    "filepath = \"../datasets/dupedata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>lname</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>exercise</th>\n",
       "      <th>hours</th>\n",
       "      <th>grade</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marcia</td>\n",
       "      <td>Pugh</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>82.4</td>\n",
       "      <td>9253 Richardson Road, Matawan, NJ 07747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kadeem</td>\n",
       "      <td>Morrison</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.2</td>\n",
       "      <td>33 Spring Dr., Taunton, MA 02780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nash</td>\n",
       "      <td>Powell</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>79.3</td>\n",
       "      <td>41 Hill Avenue, Mentor, OH 44060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noelani</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>83.2</td>\n",
       "      <td>8839 Marshall St., Miami, FL 33125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noelani</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>87.4</td>\n",
       "      <td>8304 Charles Rd., Lewis Center, OH 43035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fname     lname  gender  age  exercise  hours  grade  \\\n",
       "0   Marcia      Pugh  female   17         3     10   82.4   \n",
       "1   Kadeem  Morrison    male   18         4      4   78.2   \n",
       "2     Nash    Powell    male   18         5      9   79.3   \n",
       "3  Noelani    Wagner  female   14         2      7   83.2   \n",
       "4  Noelani    Cherry  female   18         4     15   87.4   \n",
       "\n",
       "                                    address  \n",
       "0   9253 Richardson Road, Matawan, NJ 07747  \n",
       "1          33 Spring Dr., Taunton, MA 02780  \n",
       "2          41 Hill Avenue, Mentor, OH 44060  \n",
       "3        8839 Marshall St., Miami, FL 33125  \n",
       "4  8304 Charles Rd., Lewis Center, OH 43035  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the contents in file and make a dataframe\n",
    "#show first 5 rows of dataframe\n",
    "dupe_df = pd.read_csv(filepath)\n",
    "dupe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Using the dataframe in the previous exercise, select all the rows where students received a grade lower than 60 (they need a teacher conference on how to improve for the next test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>lname</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>exercise</th>\n",
       "      <th>hours</th>\n",
       "      <th>grade</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Abbot</td>\n",
       "      <td>Hall</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>58.9</td>\n",
       "      <td>84 Rock Creek Lane, Durham, NC 27703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>970 SW. Second Ave., Cedar Falls, IA 50613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Lacey</td>\n",
       "      <td>Nieves</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57.9</td>\n",
       "      <td>38 West Brickyard Avenue, Roslindale, MA 02131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Alika</td>\n",
       "      <td>Poole</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9282 Purple Finch Lane, Lexington, NC 27292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Ciaran</td>\n",
       "      <td>Gay</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>59.3</td>\n",
       "      <td>157 Bridge Street, Corona, NY 11368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Keegan</td>\n",
       "      <td>Rasmussen</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>876 East Pilgrim Street, Chelmsford, MA 01824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Isaiah</td>\n",
       "      <td>Harrington</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>58.9</td>\n",
       "      <td>47 Mill Pond St., Haines City, FL 33844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>Selma</td>\n",
       "      <td>Stout</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>5 Pierce St., Chester, PA 19013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Willa</td>\n",
       "      <td>Byers</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>59.2</td>\n",
       "      <td>9466 Wayne Lane, Torrington, CT 06790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>Jenna</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>56.3</td>\n",
       "      <td>8829 Shore Dr., Hopewell Junction, NY 12533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>Levi</td>\n",
       "      <td>Coleman</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>55.9</td>\n",
       "      <td>9453 Laurel Street, Jersey City, NJ 07302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>Fitzgerald</td>\n",
       "      <td>Goff</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>59.8</td>\n",
       "      <td>3 West Shipley Rd., Langhorne, PA 19047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>Gail</td>\n",
       "      <td>Mcneil</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>56.1</td>\n",
       "      <td>8409A Spruce St., Fishers, IN 46037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>Xanthus</td>\n",
       "      <td>Mcneil</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>59.8</td>\n",
       "      <td>226 Redwood Lane, Boynton Beach, FL 33435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fname       lname  gender  age  exercise  hours  grade  \\\n",
       "340        Abbot        Hall    male   16         4      3   58.9   \n",
       "410        Linda     Baldwin  female   16         5      2   59.0   \n",
       "556        Lacey      Nieves  female   18         1      2   57.9   \n",
       "664        Alika       Poole  female   19         2     16   32.0   \n",
       "672       Ciaran         Gay    male   19         4      3   59.3   \n",
       "972       Keegan   Rasmussen    male   19         4      3   43.0   \n",
       "1068      Isaiah  Harrington    male   17         1      4   58.9   \n",
       "1207       Selma       Stout  female   19         2      3   59.4   \n",
       "1237       Willa       Byers  female   14         2      4   59.2   \n",
       "1494       Jenna      Wagner  female   16         1      3   56.3   \n",
       "1876        Levi     Coleman    male   19         3      3   55.9   \n",
       "1888  Fitzgerald        Goff    male   18         1      4   59.8   \n",
       "1916        Gail      Mcneil  female   17         2      3   56.1   \n",
       "1930     Xanthus      Mcneil    male   16         3      4   59.8   \n",
       "\n",
       "                                             address  \n",
       "340             84 Rock Creek Lane, Durham, NC 27703  \n",
       "410       970 SW. Second Ave., Cedar Falls, IA 50613  \n",
       "556   38 West Brickyard Avenue, Roslindale, MA 02131  \n",
       "664      9282 Purple Finch Lane, Lexington, NC 27292  \n",
       "672              157 Bridge Street, Corona, NY 11368  \n",
       "972    876 East Pilgrim Street, Chelmsford, MA 01824  \n",
       "1068         47 Mill Pond St., Haines City, FL 33844  \n",
       "1207                 5 Pierce St., Chester, PA 19013  \n",
       "1237           9466 Wayne Lane, Torrington, CT 06790  \n",
       "1494     8829 Shore Dr., Hopewell Junction, NY 12533  \n",
       "1876       9453 Laurel Street, Jersey City, NJ 07302  \n",
       "1888         3 West Shipley Rd., Langhorne, PA 19047  \n",
       "1916             8409A Spruce St., Fishers, IN 46037  \n",
       "1930       226 Redwood Lane, Boynton Beach, FL 33435  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choose the row labels (.loc) from the dataframe\n",
    "#where the \"grade\" column is less than 60\n",
    "dupe_df.loc[dupe_df['grade'] < 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Using the dataframe from Exercise 1, select all the rows where a student received a grade of 100 and change their grade to 103 (extra credit!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the rows in the dataframe's \"grade\" column that are 100\n",
    "#then in the \"grade\" column, set those values to be 103\n",
    "dupe_df.loc[dupe_df['grade'] == 100, 'grade'] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>lname</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>exercise</th>\n",
       "      <th>hours</th>\n",
       "      <th>grade</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Libby</td>\n",
       "      <td>Guzman</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>666 S. Pennington Rd., Dover, NH 03820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ivor</td>\n",
       "      <td>Arnold</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7027 Magnolia Dr., Catonsville, MD 21228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Quemby</td>\n",
       "      <td>Justice</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>346 Birchpond Court, Decatur, GA 30030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Sage</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9721B Green Dr., Fairhope, AL 36532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Sophia</td>\n",
       "      <td>Gordon</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7672 Smoky Hollow Street, Hillsboro, OR 97124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Ciaran</td>\n",
       "      <td>Johns</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7350 Creek Avenue, Upper Marlboro, MD 20772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Uriah</td>\n",
       "      <td>Cummings</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>444 West Homestead Rd., Lebanon, PA 17042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Phyllis</td>\n",
       "      <td>Walters</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>33 Smith St., Hephzibah, GA 30815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Rose</td>\n",
       "      <td>Middleton</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>979 Andover Street, Cockeysville, MD 21030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Kamal</td>\n",
       "      <td>Walton</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9125 Edgemont Lane, Attleboro, MA 02703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Lysandra</td>\n",
       "      <td>Copeland</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>20 Talbot Drive, Fort Lauderdale, FL 33308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Thor</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>208 Plymouth St., Grove City, OH 43123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Kadeem</td>\n",
       "      <td>Marshall</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>56 North Glen Creek St., San Lorenzo, CA 94580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Jacob</td>\n",
       "      <td>Gray</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8323 Alton Court, Clementon, NJ 08021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Kaden</td>\n",
       "      <td>Grant</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>103.0</td>\n",
       "      <td>73 SW. Leeton Ridge Road, Homestead, FL 33030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Myra</td>\n",
       "      <td>Parrish</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>103.0</td>\n",
       "      <td>854 3rd Ave., Nanuet, NY 10954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Inez</td>\n",
       "      <td>Stephenson</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>51 Academy St., Roselle, IL 60172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Declan</td>\n",
       "      <td>Manning</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7993 E. Harvey Ave., Springfield, PA 19064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Dai</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2 Pilgrim Road, Alexandria, VA 22304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Kiara</td>\n",
       "      <td>Singleton</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9800 Atlantic St., Whitestone, NY 11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Ali</td>\n",
       "      <td>Franks</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>78 Essex Road, Stillwater, MN 55082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Gwendolyn</td>\n",
       "      <td>Vazquez</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>550 Selby St., Louisville, KY 40207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Winters</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>59 Greenrose St., Conyers, GA 30012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Camille</td>\n",
       "      <td>Barr</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9665 S. Spring Rd., Kaukauna, WI 54130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Sylvester</td>\n",
       "      <td>Payne</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>242 Goldfield Ave., Encino, CA 91316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Ruth</td>\n",
       "      <td>Bowman</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8621 Shub Farm Ave., Ocean Springs, MS 39564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Janna</td>\n",
       "      <td>Moran</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4 Belmont St., Fremont, OH 43420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Erich</td>\n",
       "      <td>Stone</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>694 W. Heritage Road, Bedford, OH 44146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Lila</td>\n",
       "      <td>Wall</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>546 Fulton Lane, Warren, MI 48089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Josephine</td>\n",
       "      <td>Rivers</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8867 Jackson Dr., Newark, NJ 07103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Harriet</td>\n",
       "      <td>Long</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>797 Rockcrest Avenue, Lakewood, NJ 08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>Shaine</td>\n",
       "      <td>Mcleod</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8400 Brickell Drive, Clayton, NC 27520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>September</td>\n",
       "      <td>Norris</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>326 Birch Hill Street, Kent, OH 44240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>Asher</td>\n",
       "      <td>Guerrero</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>103.0</td>\n",
       "      <td>28 North Charles Road, Lithonia, GA 30038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>Clio</td>\n",
       "      <td>Glover</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>103.0</td>\n",
       "      <td>405 St Margarets Drive, Tampa, FL 33604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>Cassady</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8233 Thomas Ave., North Miami Beach, FL 33160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Blossom</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>614 Locust Street, Winter Springs, FL 32708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>Cash</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>48 King Circle, Griffin, GA 30223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>Igor</td>\n",
       "      <td>Conway</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7859 Carriage Rd., Wilmington, MA 01887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>Denise</td>\n",
       "      <td>Sloan</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>36 Bowman Dr., Fort Dodge, IA 50501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Honorato</td>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>64 Mill Pond Street, Panama City, FL 32404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>Avram</td>\n",
       "      <td>Huber</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>36 S. Pacific Ave., Palm City, FL 34990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Clayton</td>\n",
       "      <td>Yates</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9528 Miller Drive, Klamath Falls, OR 97603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>Gay</td>\n",
       "      <td>Carlson</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>805 Lakeview Avenue, Villa Park, IL 60181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>Carol</td>\n",
       "      <td>Dillard</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>929 Pilgrim Road, Venice, FL 34293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>Naomi</td>\n",
       "      <td>Strong</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>507 E. Fifth Lane, Natick, MA 01760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>Phillip</td>\n",
       "      <td>Savage</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>579 High Ridge Rd., Matawan, NJ 07747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>Maxwell</td>\n",
       "      <td>Blake</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30 Hawthorne Ave., Norfolk, VA 23503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>Louis</td>\n",
       "      <td>Joyner</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7875 Tarkiln Hill Court, Windermere, FL 34786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>Vera</td>\n",
       "      <td>Russell</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>103.0</td>\n",
       "      <td>122 S. Pulaski St., Wausau, WI 54401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>Yael</td>\n",
       "      <td>Hatfield</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9612 Sherman Avenue, Elk River, MN 55330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>Murphy</td>\n",
       "      <td>Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>88 Garden Street, Union, NJ 07083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>Juliet</td>\n",
       "      <td>Good</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>103.0</td>\n",
       "      <td>69 Lake Forest Lane, Midlothian, VA 23112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>Phelan</td>\n",
       "      <td>Frye</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>9614 Winding Way St., Stone Mountain, GA 30083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>Adena</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>575 Beech Street, Upper Marlboro, MD 20772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>Brianna</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>female</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8493 Locust Ave., Longwood, FL 32779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>Kai</td>\n",
       "      <td>Woodard</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>103.0</td>\n",
       "      <td>37 Addison St., Eastpointe, MI 48021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>Leah</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>103.0</td>\n",
       "      <td>652 Pine Drive, Mountain View, CA 94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Geraldine</td>\n",
       "      <td>Peterson</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0</td>\n",
       "      <td>78 Morris Street, East Northport, NY 11731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Libby</td>\n",
       "      <td>Guzman</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>666 S. Pennington Rd., Dover, NH 03820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname       lname  gender  age  exercise  hours  grade  \\\n",
       "17        Libby      Guzman  female   19         1     19  103.0   \n",
       "36         Ivor      Arnold    male   19         4     20  103.0   \n",
       "77       Quemby     Justice  female   14         2     17  103.0   \n",
       "101        Sage   Cleveland  female   19         2     20  103.0   \n",
       "109      Sophia      Gordon  female   19         4     17  103.0   \n",
       "165      Ciaran       Johns    male   16         4     15  103.0   \n",
       "226       Uriah    Cummings    male   18         3     20  103.0   \n",
       "249     Phyllis     Walters  female   18         4     19  103.0   \n",
       "252        Rose   Middleton  female   15         2     20  103.0   \n",
       "303       Kamal      Walton    male   14         1     17  103.0   \n",
       "321    Lysandra    Copeland  female   19         5     19  103.0   \n",
       "325        Thor       Ramos    male   17         3     18  103.0   \n",
       "355      Kadeem    Marshall    male   17         5     18  103.0   \n",
       "382       Jacob        Gray    male   15         3     17  103.0   \n",
       "434       Kaden       Grant  female   17         5     14  103.0   \n",
       "457        Myra     Parrish  female   19         5     15  103.0   \n",
       "459        Inez  Stephenson  female   17         5     17  103.0   \n",
       "473      Declan     Manning    male   18         4     16  103.0   \n",
       "508         Dai     Osborne  female   19         5     20  103.0   \n",
       "610       Kiara   Singleton  female   16         4     19  103.0   \n",
       "616         Ali      Franks    male   18         5     20  103.0   \n",
       "621   Gwendolyn     Vazquez  female   19         5     19  103.0   \n",
       "644       Drake     Winters    male   17         4     19  103.0   \n",
       "661     Camille        Barr  female   14         4     14  103.0   \n",
       "690   Sylvester       Payne    male   17         5     20  103.0   \n",
       "698        Ruth      Bowman  female   18         3     18  103.0   \n",
       "701       Janna       Moran  female   17         5     17  103.0   \n",
       "757       Erich       Stone    male   14         5     17  103.0   \n",
       "767        Lila        Wall  female   17         5     18  103.0   \n",
       "787   Josephine      Rivers  female   18         2     17  103.0   \n",
       "...         ...         ...     ...  ...       ...    ...    ...   \n",
       "1421    Harriet        Long  female   17         3     17  103.0   \n",
       "1426     Shaine      Mcleod  female   16         2     18  103.0   \n",
       "1481  September      Norris  female   15         1     20  103.0   \n",
       "1545      Asher    Guerrero    male   14         4     15  103.0   \n",
       "1605       Clio      Glover  female   15         4     16  103.0   \n",
       "1629    Cassady        Ruiz  female   16         2     18  103.0   \n",
       "1634    Blossom    Gonzalez  female   17         4     18  103.0   \n",
       "1639   Colorado        Cash    male   16         5     18  103.0   \n",
       "1649       Igor      Conway    male   17         1     17  103.0   \n",
       "1650     Denise       Sloan  female   18         4     20  103.0   \n",
       "1659   Honorato   Gutierrez    male   16         5     17  103.0   \n",
       "1665      Avram       Huber    male   18         3     20  103.0   \n",
       "1680    Clayton       Yates    male   16         5     14  103.0   \n",
       "1719        Gay     Carlson  female   18         2     20  103.0   \n",
       "1724      Carol     Dillard  female   18         5     17  103.0   \n",
       "1734      Naomi      Strong  female   15         2     20  103.0   \n",
       "1840    Phillip      Savage    male   19         2     19  103.0   \n",
       "1841    Maxwell       Blake    male   15         2     17  103.0   \n",
       "1842      Louis      Joyner    male   19         2     19  103.0   \n",
       "1844       Vera     Russell  female   18         4     16  103.0   \n",
       "1850       Yael    Hatfield  female   19         2     18  103.0   \n",
       "1859     Murphy     Michael    male   14         1     19  103.0   \n",
       "1899     Juliet        Good  female   14         5     15  103.0   \n",
       "1928     Phelan        Frye    male   16         5     19  103.0   \n",
       "1939      Adena    Robinson  female   14         3     19  103.0   \n",
       "1951    Brianna    Holloway  female   18         4     18  103.0   \n",
       "1985        Kai     Woodard  female   17         5     17  103.0   \n",
       "1987       Leah    Lawrence  female   15         5     15  103.0   \n",
       "2002  Geraldine    Peterson  female   16         4     18  103.0   \n",
       "2014      Libby      Guzman  female   19         1     19  103.0   \n",
       "\n",
       "                                             address  \n",
       "17            666 S. Pennington Rd., Dover, NH 03820  \n",
       "36          7027 Magnolia Dr., Catonsville, MD 21228  \n",
       "77            346 Birchpond Court, Decatur, GA 30030  \n",
       "101              9721B Green Dr., Fairhope, AL 36532  \n",
       "109    7672 Smoky Hollow Street, Hillsboro, OR 97124  \n",
       "165      7350 Creek Avenue, Upper Marlboro, MD 20772  \n",
       "226        444 West Homestead Rd., Lebanon, PA 17042  \n",
       "249                33 Smith St., Hephzibah, GA 30815  \n",
       "252       979 Andover Street, Cockeysville, MD 21030  \n",
       "303          9125 Edgemont Lane, Attleboro, MA 02703  \n",
       "321       20 Talbot Drive, Fort Lauderdale, FL 33308  \n",
       "325           208 Plymouth St., Grove City, OH 43123  \n",
       "355   56 North Glen Creek St., San Lorenzo, CA 94580  \n",
       "382            8323 Alton Court, Clementon, NJ 08021  \n",
       "434    73 SW. Leeton Ridge Road, Homestead, FL 33030  \n",
       "457                   854 3rd Ave., Nanuet, NY 10954  \n",
       "459                51 Academy St., Roselle, IL 60172  \n",
       "473       7993 E. Harvey Ave., Springfield, PA 19064  \n",
       "508             2 Pilgrim Road, Alexandria, VA 22304  \n",
       "610          9800 Atlantic St., Whitestone, NY 11357  \n",
       "616              78 Essex Road, Stillwater, MN 55082  \n",
       "621              550 Selby St., Louisville, KY 40207  \n",
       "644              59 Greenrose St., Conyers, GA 30012  \n",
       "661           9665 S. Spring Rd., Kaukauna, WI 54130  \n",
       "690             242 Goldfield Ave., Encino, CA 91316  \n",
       "698     8621 Shub Farm Ave., Ocean Springs, MS 39564  \n",
       "701                 4 Belmont St., Fremont, OH 43420  \n",
       "757          694 W. Heritage Road, Bedford, OH 44146  \n",
       "767                546 Fulton Lane, Warren, MI 48089  \n",
       "787               8867 Jackson Dr., Newark, NJ 07103  \n",
       "...                                              ...  \n",
       "1421        797 Rockcrest Avenue, Lakewood, NJ 08701  \n",
       "1426          8400 Brickell Drive, Clayton, NC 27520  \n",
       "1481           326 Birch Hill Street, Kent, OH 44240  \n",
       "1545       28 North Charles Road, Lithonia, GA 30038  \n",
       "1605         405 St Margarets Drive, Tampa, FL 33604  \n",
       "1629   8233 Thomas Ave., North Miami Beach, FL 33160  \n",
       "1634     614 Locust Street, Winter Springs, FL 32708  \n",
       "1639               48 King Circle, Griffin, GA 30223  \n",
       "1649         7859 Carriage Rd., Wilmington, MA 01887  \n",
       "1650             36 Bowman Dr., Fort Dodge, IA 50501  \n",
       "1659      64 Mill Pond Street, Panama City, FL 32404  \n",
       "1665         36 S. Pacific Ave., Palm City, FL 34990  \n",
       "1680      9528 Miller Drive, Klamath Falls, OR 97603  \n",
       "1719       805 Lakeview Avenue, Villa Park, IL 60181  \n",
       "1724              929 Pilgrim Road, Venice, FL 34293  \n",
       "1734             507 E. Fifth Lane, Natick, MA 01760  \n",
       "1840           579 High Ridge Rd., Matawan, NJ 07747  \n",
       "1841            30 Hawthorne Ave., Norfolk, VA 23503  \n",
       "1842   7875 Tarkiln Hill Court, Windermere, FL 34786  \n",
       "1844            122 S. Pulaski St., Wausau, WI 54401  \n",
       "1850        9612 Sherman Avenue, Elk River, MN 55330  \n",
       "1859               88 Garden Street, Union, NJ 07083  \n",
       "1899       69 Lake Forest Lane, Midlothian, VA 23112  \n",
       "1928  9614 Winding Way St., Stone Mountain, GA 30083  \n",
       "1939      575 Beech Street, Upper Marlboro, MD 20772  \n",
       "1951            8493 Locust Ave., Longwood, FL 32779  \n",
       "1985            37 Addison St., Eastpointe, MI 48021  \n",
       "1987         652 Pine Drive, Mountain View, CA 94043  \n",
       "2002      78 Morris Street, East Northport, NY 11731  \n",
       "2014          666 S. Pennington Rd., Dover, NH 03820  \n",
       "\n",
       "[88 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that the grades were changed\n",
    "#choose rows where \"grade\" is 103\n",
    "dupe_df.loc[dupe_df['grade'] == 103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "Load in the `travel_times.csv` file as a dataframe. Drop the `Comments` column. Then remove rows from the dataframe that have missing values and assign the resulting dataframe as a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>GoingTo</th>\n",
       "      <th>Distance</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>AvgSpeed</th>\n",
       "      <th>AvgMovingSpeed</th>\n",
       "      <th>FuelEconomy</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>MovingTime</th>\n",
       "      <th>Take407All</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>16:37</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.29</td>\n",
       "      <td>127.4</td>\n",
       "      <td>78.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3</td>\n",
       "      <td>36.3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>08:20</td>\n",
       "      <td>Friday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>51.63</td>\n",
       "      <td>130.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>88.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>16:17</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.27</td>\n",
       "      <td>127.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>85.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.5</td>\n",
       "      <td>35.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>07:53</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.17</td>\n",
       "      <td>132.3</td>\n",
       "      <td>74.2</td>\n",
       "      <td>82.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.8</td>\n",
       "      <td>35.6</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>18:57</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.15</td>\n",
       "      <td>136.2</td>\n",
       "      <td>83.4</td>\n",
       "      <td>88.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.8</td>\n",
       "      <td>34.8</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date StartTime  DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \\\n",
       "0  1/6/2012     16:37     Friday    Home     51.29     127.4      78.3   \n",
       "1  1/6/2012     08:20     Friday     GSK     51.63     130.3      81.8   \n",
       "2  1/4/2012     16:17  Wednesday    Home     51.27     127.4      82.0   \n",
       "3  1/4/2012     07:53  Wednesday     GSK     49.17     132.3      74.2   \n",
       "4  1/3/2012     18:57    Tuesday    Home     51.15     136.2      83.4   \n",
       "\n",
       "   AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Comments  \n",
       "0            84.8         NaN       39.3        36.3         No      NaN  \n",
       "1            88.9         NaN       37.9        34.9         No      NaN  \n",
       "2            85.8         NaN       37.5        35.9         No      NaN  \n",
       "3            82.9         NaN       39.8        35.6         No      NaN  \n",
       "4            88.1         NaN       36.8        34.8         No      NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the file into a dataframe\n",
    "#set the dataframe to the variable name \"travel_df\"\n",
    "travel_df = pd.read_csv(\"../datasets/travel_times.csv\")\n",
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the column (axis=1) \"Comment\"\n",
    "#this makes a change permanently (inplace=True) to the variable \"travel_df\"\n",
    "travel_df.drop('Comments', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               0\n",
       "StartTime          0\n",
       "DayOfWeek          0\n",
       "GoingTo            0\n",
       "Distance           0\n",
       "MaxSpeed           0\n",
       "AvgSpeed           0\n",
       "AvgMovingSpeed     0\n",
       "FuelEconomy       17\n",
       "TotalTime          0\n",
       "MovingTime         0\n",
       "Take407All         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify how many missing values are in the dataframe\n",
    "travel_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any row with any missing values\n",
    "#make change permanently (inplace=True)\n",
    "travel_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "StartTime         0\n",
       "DayOfWeek         0\n",
       "GoingTo           0\n",
       "Distance          0\n",
       "MaxSpeed          0\n",
       "AvgSpeed          0\n",
       "AvgMovingSpeed    0\n",
       "FuelEconomy       0\n",
       "TotalTime         0\n",
       "MovingTime        0\n",
       "Take407All        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that there are no missing values in the columns\n",
    "travel_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Using the dataframe from the exercise above (w/ no missing values), create bins that will categorize the AvgSpeed column as \"slow\" or \"fast\", and make a new column called \"Speed\" to hold those new values. Values less than 75 are \"slow\" and everything above is \"fast\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a list of the categories that will be in the new column\n",
    "categories = [\"slow\", \"fast\"]\n",
    "\n",
    "#make a list of the interval cutoffs\n",
    "bins = [0, 75, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a new column called \"Speed\"\n",
    "#using the \"AvgSpeed\" column, use the \"bins\" list to make the group categories\n",
    "travel_df['Speed'] = pd.cut(travel_df['AvgSpeed'], bins, labels=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>GoingTo</th>\n",
       "      <th>Distance</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>AvgSpeed</th>\n",
       "      <th>AvgMovingSpeed</th>\n",
       "      <th>FuelEconomy</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>MovingTime</th>\n",
       "      <th>Take407All</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>17:31</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.37</td>\n",
       "      <td>123.2</td>\n",
       "      <td>82.9</td>\n",
       "      <td>87.3</td>\n",
       "      <td>-</td>\n",
       "      <td>37.2</td>\n",
       "      <td>35.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>07:34</td>\n",
       "      <td>Monday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.01</td>\n",
       "      <td>128.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>85.9</td>\n",
       "      <td>-</td>\n",
       "      <td>37.9</td>\n",
       "      <td>34.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/23/2011</td>\n",
       "      <td>08:01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>52.91</td>\n",
       "      <td>130.3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>17:19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.17</td>\n",
       "      <td>122.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>78.1</td>\n",
       "      <td>8.89</td>\n",
       "      <td>43.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>08:16</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.15</td>\n",
       "      <td>129.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.4</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date StartTime DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \\\n",
       "6     1/2/2012     17:31    Monday    Home     51.37     123.2      82.9   \n",
       "7     1/2/2012     07:34    Monday     GSK     49.01     128.3      77.5   \n",
       "8   12/23/2011     08:01    Friday     GSK     52.91     130.3      80.9   \n",
       "9   12/22/2011     17:19  Thursday    Home     51.17     122.3      70.6   \n",
       "10  12/22/2011     08:16  Thursday     GSK     49.15     129.4      74.0   \n",
       "\n",
       "    AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Speed  \n",
       "6             87.3           -       37.2        35.3         No  fast  \n",
       "7             85.9           -       37.9        34.3         No  fast  \n",
       "8             88.3        8.89       39.3        36.0         No  fast  \n",
       "9             78.1        8.89       43.5        39.3         No  slow  \n",
       "10            81.4        8.89       39.8        36.2         No  slow  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the first 5 rows of dataframe to see new column\n",
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Using the dataframe in the previous exercise, make a new column called `Police` where all the values are \"no\" (they were never stopped by police for speeding while traveling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left side of assignment operator (=) is the new column name in the dataframe\n",
    "#right side of assignment operator is the value that will be put in every row\n",
    "travel_df['Police'] = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>GoingTo</th>\n",
       "      <th>Distance</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>AvgSpeed</th>\n",
       "      <th>AvgMovingSpeed</th>\n",
       "      <th>FuelEconomy</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>MovingTime</th>\n",
       "      <th>Take407All</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Police</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>17:31</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.37</td>\n",
       "      <td>123.2</td>\n",
       "      <td>82.9</td>\n",
       "      <td>87.3</td>\n",
       "      <td>-</td>\n",
       "      <td>37.2</td>\n",
       "      <td>35.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>07:34</td>\n",
       "      <td>Monday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.01</td>\n",
       "      <td>128.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>85.9</td>\n",
       "      <td>-</td>\n",
       "      <td>37.9</td>\n",
       "      <td>34.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/23/2011</td>\n",
       "      <td>08:01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>52.91</td>\n",
       "      <td>130.3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>17:19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.17</td>\n",
       "      <td>122.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>78.1</td>\n",
       "      <td>8.89</td>\n",
       "      <td>43.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>08:16</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.15</td>\n",
       "      <td>129.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.4</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date StartTime DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \\\n",
       "6     1/2/2012     17:31    Monday    Home     51.37     123.2      82.9   \n",
       "7     1/2/2012     07:34    Monday     GSK     49.01     128.3      77.5   \n",
       "8   12/23/2011     08:01    Friday     GSK     52.91     130.3      80.9   \n",
       "9   12/22/2011     17:19  Thursday    Home     51.17     122.3      70.6   \n",
       "10  12/22/2011     08:16  Thursday     GSK     49.15     129.4      74.0   \n",
       "\n",
       "    AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Speed Police  \n",
       "6             87.3           -       37.2        35.3         No  fast     no  \n",
       "7             85.9           -       37.9        34.3         No  fast     no  \n",
       "8             88.3        8.89       39.3        36.0         No  fast     no  \n",
       "9             78.1        8.89       43.5        39.3         No  slow     no  \n",
       "10            81.4        8.89       39.8        36.2         No  slow     no  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify new column w/ first 5 rows in dataframe\n",
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Using the dataframe from the previous exercise, pick a method (Standard Deviation or Interquartile Range) and remove the outliers from the \"FuelEconomy\" column.\n",
    "\n",
    "***Note***: If you choose the Standard Deviation method, calculate the outliers that are outside of two (2) standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert --8.898.898.898.898.898.898.898.899.089.089.089.089.089.089.089.089.769.769.769.769.769.769.769.169.169.169.39.39.39.39.39.310.0510.0510.0510.059.539.539.539.539.539.539.539.539.359.359.359.359.359.359.359.358.328.328.328.328.328.328.328.328.978.978.978.978.978.978.758.758.758.758.758.758.758.758.758.758.757.817.817.977.977.977.977.977.977.977.977.977.978.938.938.938.938.318.318.318.318.318.318.338.338.338.338.338.338.338.338.338.338.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.548.548.548.548.548.548.548.548.548.548.378.378.378.378.378.378.378.378.378.378.548.548.548.548.548.548.548.548.548.548.488.488.488.488.488.488.488.488.458.458.458.458.458.458.458.458.458.458.288.288.287.897.897.897.897.897.89 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '--8.898.898.898.898.898.898.898.899.089.089.089.089.089.089.089.089.769.769.769.769.769.769.769.169.169.169.39.39.39.39.39.310.0510.0510.0510.059.539.539.539.539.539.539.539.539.359.359.359.359.359.359.359.358.328.328.328.328.328.328.328.328.978.978.978.978.978.978.758.758.758.758.758.758.758.758.758.758.757.817.817.977.977.977.977.977.977.977.977.977.978.938.938.938.938.318.318.318.318.318.318.338.338.338.338.338.338.338.338.338.338.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.548.548.548.548.548.548.548.548.548.548.378.378.378.378.378.378.378.378.378.378.548.548.548.548.548.548.548.548.548.548.488.488.488.488.488.488.488.488.458.458.458.458.458.458.458.458.458.458.288.288.287.897.897.897.897.897.89'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 raise TypeError('Could not convert {value!s} to numeric'\n\u001b[1;32m-> 1170\u001b[1;33m                                 .format(value=x))\n\u001b[0m\u001b[0;32m   1171\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert --8.898.898.898.898.898.898.898.899.089.089.089.089.089.089.089.089.769.769.769.769.769.769.769.169.169.169.39.39.39.39.39.310.0510.0510.0510.059.539.539.539.539.539.539.539.539.359.359.359.359.359.359.359.358.328.328.328.328.328.328.328.328.978.978.978.978.978.978.758.758.758.758.758.758.758.758.758.758.757.817.817.977.977.977.977.977.977.977.977.977.978.938.938.938.938.318.318.318.318.318.318.338.338.338.338.338.338.338.338.338.338.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.548.548.548.548.548.548.548.548.548.548.378.378.378.378.378.378.378.378.378.378.548.548.548.548.548.548.548.548.548.548.488.488.488.488.488.488.488.488.458.458.458.458.458.458.458.458.458.458.288.288.287.897.897.897.897.897.89 to numeric",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '--8.898.898.898.898.898.898.898.899.089.089.089.089.089.089.089.089.769.769.769.769.769.769.769.169.169.169.39.39.39.39.39.310.0510.0510.0510.059.539.539.539.539.539.539.539.539.359.359.359.359.359.359.359.358.328.328.328.328.328.328.328.328.978.978.978.978.978.978.758.758.758.758.758.758.758.758.758.758.757.817.817.977.977.977.977.977.977.977.977.977.978.938.938.938.938.318.318.318.318.318.318.338.338.338.338.338.338.338.338.338.338.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.548.548.548.548.548.548.548.548.548.548.378.378.378.378.378.378.378.378.378.378.548.548.548.548.548.548.548.548.548.548.488.488.488.488.488.488.488.488.458.458.458.458.458.458.458.458.458.458.288.288.287.897.897.897.897.897.89'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-e83ec79936ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfuel_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtravel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FuelEconomy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfuel_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtravel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FuelEconomy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10954\u001b[0m                                       skipna=skipna)\n\u001b[0;32m  10955\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[1;32m> 10956\u001b[1;33m                             numeric_only=numeric_only)\n\u001b[0m\u001b[0;32m  10957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10958\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   3628\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[0;32m   3629\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m         \u001b[1;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                     \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 raise TypeError('Could not convert {value!s} to numeric'\n\u001b[1;32m-> 1170\u001b[1;33m                                 .format(value=x))\n\u001b[0m\u001b[0;32m   1171\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert --8.898.898.898.898.898.898.898.899.089.089.089.089.089.089.089.089.769.769.769.769.769.769.769.169.169.169.39.39.39.39.39.310.0510.0510.0510.059.539.539.539.539.539.539.539.539.359.359.359.359.359.359.359.358.328.328.328.328.328.328.328.328.978.978.978.978.978.978.758.758.758.758.758.758.758.758.758.758.757.817.817.977.977.977.977.977.977.977.977.977.978.938.938.938.938.318.318.318.318.318.318.338.338.338.338.338.338.338.338.338.338.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.58.548.548.548.548.548.548.548.548.548.548.378.378.378.378.378.378.378.378.378.378.548.548.548.548.548.548.548.548.548.548.488.488.488.488.488.488.488.488.458.458.458.458.458.458.458.458.458.458.288.288.287.897.897.897.897.897.89 to numeric"
     ]
    }
   ],
   "source": [
    "#get the mean and standard deviation for the \"FuelEconomy\" column\n",
    "#there is a ValueError; scroll down to resolve\n",
    "fuel_mean = travel_df['FuelEconomy'].mean()\n",
    "fuel_std = travel_df['FuelEconomy'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "\n",
    "In the `FuelEconomy` column, some of the values are dashes (which are strings). The code below shows that the data type of the column is an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                object\n",
       "StartTime           object\n",
       "DayOfWeek           object\n",
       "GoingTo             object\n",
       "Distance           float64\n",
       "MaxSpeed           float64\n",
       "AvgSpeed           float64\n",
       "AvgMovingSpeed     float64\n",
       "FuelEconomy         object\n",
       "TotalTime          float64\n",
       "MovingTime         float64\n",
       "Take407All          object\n",
       "Speed             category\n",
       "Police              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"FuelEconomy\" column is an object (string)\n",
    "travel_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the dashes with a null value\n",
    "travel_df.loc[travel_df['FuelEconomy'] == \"-\", 'FuelEconomy'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>GoingTo</th>\n",
       "      <th>Distance</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>AvgSpeed</th>\n",
       "      <th>AvgMovingSpeed</th>\n",
       "      <th>FuelEconomy</th>\n",
       "      <th>TotalTime</th>\n",
       "      <th>MovingTime</th>\n",
       "      <th>Take407All</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Police</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>17:31</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.37</td>\n",
       "      <td>123.2</td>\n",
       "      <td>82.9</td>\n",
       "      <td>87.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.2</td>\n",
       "      <td>35.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/2/2012</td>\n",
       "      <td>07:34</td>\n",
       "      <td>Monday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.01</td>\n",
       "      <td>128.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>85.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.9</td>\n",
       "      <td>34.3</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/23/2011</td>\n",
       "      <td>08:01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>52.91</td>\n",
       "      <td>130.3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>No</td>\n",
       "      <td>fast</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>17:19</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Home</td>\n",
       "      <td>51.17</td>\n",
       "      <td>122.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>78.1</td>\n",
       "      <td>8.89</td>\n",
       "      <td>43.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/22/2011</td>\n",
       "      <td>08:16</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>GSK</td>\n",
       "      <td>49.15</td>\n",
       "      <td>129.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.4</td>\n",
       "      <td>8.89</td>\n",
       "      <td>39.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>No</td>\n",
       "      <td>slow</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date StartTime DayOfWeek GoingTo  Distance  MaxSpeed  AvgSpeed  \\\n",
       "6     1/2/2012     17:31    Monday    Home     51.37     123.2      82.9   \n",
       "7     1/2/2012     07:34    Monday     GSK     49.01     128.3      77.5   \n",
       "8   12/23/2011     08:01    Friday     GSK     52.91     130.3      80.9   \n",
       "9   12/22/2011     17:19  Thursday    Home     51.17     122.3      70.6   \n",
       "10  12/22/2011     08:16  Thursday     GSK     49.15     129.4      74.0   \n",
       "\n",
       "    AvgMovingSpeed FuelEconomy  TotalTime  MovingTime Take407All Speed Police  \n",
       "6             87.3         NaN       37.2        35.3         No  fast     no  \n",
       "7             85.9         NaN       37.9        34.3         No  fast     no  \n",
       "8             88.3        8.89       39.3        36.0         No  fast     no  \n",
       "9             78.1        8.89       43.5        39.3         No  slow     no  \n",
       "10            81.4        8.89       39.8        36.2         No  slow     no  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the values are now NaN\n",
    "travel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"FuelEconomy\" column is still an object\n",
    "travel_df['FuelEconomy'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use lambda function to convert each value into a float\n",
    "#assign values back to 'FuelEconomy' column\n",
    "travel_df['FuelEconomy'] = travel_df['FuelEconomy'].apply(lambda value: float(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the column is a float type\n",
    "travel_df['FuelEconomy'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can finally calculate the mean and standard deviation\n",
    "fuel_mean = travel_df['FuelEconomy'].mean()\n",
    "fuel_std = travel_df['FuelEconomy'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.69059139784946, 0.5049711522198591)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the values stored in the variables\n",
    "fuel_mean, fuel_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a variable with the value of 2 standard deviations (amount of jump)\n",
    "fuel_2std = fuel_std*2\n",
    "\n",
    "#calculate the values that are 2 standard deviations above an below the mean\n",
    "#these are the cutoff values for outliers\n",
    "top_range = fuel_mean + fuel_2std\n",
    "bottom_range = fuel_mean - fuel_2std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the values of the cutoff points\n",
    "top_range, bottom_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the rows that are between the top and bottom ranges (the normal data - not outliers)\n",
    "no_outlier_df = travel_df.loc[(travel_df['FuelEconomy'] > bottom_range) & (travel_df['FuelEconomy'] < top_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    175.000000\n",
       "mean       8.616743\n",
       "std        0.420881\n",
       "min        7.810000\n",
       "25%        8.330000\n",
       "50%        8.500000\n",
       "75%        8.890000\n",
       "max        9.530000\n",
       "Name: FuelEconomy, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new summary statistics for the dataset\n",
    "#outliers have been removed\n",
    "no_outlier_df['FuelEconomy'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
